# airflow-values.yaml
# Use KubernetesExecutor for dynamic task execution in k8s
executor: "KubernetesExecutor"
# Alternative: use CeleryKubernetesExecutor to combine both approaches
# executor: "CeleryKubernetesExecutor"

# Custom Docker image with our dependencies
images:
  airflow:
    repository: localhost:5000/airflow
    tag: 0.0.1
    pullPolicy: Always
  useDefaultImageForMigration: true
    
# Disable built-in PostgreSQL as you're deploying it separately
postgresql:
  enabled: false
# Set up PostgreSQL connection
data:
  metadataConnection:
    user: airflow
    pass: airflow
    host: airflow-postgresql
    port: 5432
    db: airflow
    sslmode: disable

# Disable Redis if you're not using CeleryExecutor
# redis:
#   enabled: false  # Change to true if using CeleryExecutor

# # Configure persistence for logs 
logs:
  persistence:
    enabled: true
    existingClaim: airflow-logs-pvc

# Configure Kubernetes pod template for tasks
config:
  kubernetes_executor:
  ***REMOVED***
    worker_container_repository: localhost:5000/airflow
    worker_container_tag: 0.0.1
    
# Volume configuration for all pods
extraVolumes:
  - name: airflow-data
    persistentVolumeClaim:
      claimName: airflow-data-pvc

extraVolumeMounts:
  - name: airflow-data
    mountPath: /opt/airflow/data

# Set up web UI
webserver:
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    password: admin
    email: admin@example.com
    firstName: Admin
    lastName: User

extraEnvFrom: |
  - secretRef:
    ***REMOVED***
  - configMapRef:
      name: airflow-extra-config
      
